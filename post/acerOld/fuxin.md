# 复兴

复习工作技能

## 重点1

巩固已经会的技术。按方向复习，如：服务器，存储，网络，前端

- 服务器：tomcat,netty or jetty ,nginx
  - nginx

- 存储：mysql ,redis ,数据库原理，分库分表

- [ ] mysql

- [ ] redis
- [ ] 数据库原理
- [x] 分库分表
- [ ] mybatis

- 语言： java 及相关框架（Spring*），jvm
- [ ] java 基础
- [ ] java 高级应用
- [ ] jvm
- [ ] Spring-boot,SpringMVC

## 重点2

优先复习数据结构与算法，jvm操作系统相关

要求：

- 快速手写冒泡及其改进算法，快排算法，链表操作算法
- 结合操作系统知识学习 jvm 

## 次重点

学习后端开发不熟悉的技术，如：elasticsearch,dubbo,kafaka,mq,golang.

用一个项目将这些技术都用上。

分布式，消息，存储，搜索。 

----

开始

# 分库分表

[数据库分库分表思路](https://mp.weixin.qq.com/s?src=11×tamp=1577859241&ver=2069&signature=YXsTa*72fHzzHtqS2UuxbY-c6RWsZTEusBWCQtfNpZDrNjlqP0ebDt5TnlMY1bNlSGUldvHw3ZOW-1MDtWmo632X2vZr23Eqd-DemwnFa9-IaKRJ1d9O9IUlJfr668EN&new=1 )

分库和分表是两个概念。指的是将原先一张表中的内容分到几张表或者几个库中存储。

## 拆分方式

一般有**垂直拆分**和**水平拆分**。就是按字面理解，是相对于一张表而言的。把一张存有数据的表看成是一个表格，则水平拆分就是将表格**按行拆分**，这样拆分出来的部分包含的字段都相同，只是数据不同；同样的，垂直拆分就是将一个表格**按列拆分**，拆出来的各个部分包含的字段和数据都不同，一般会将常用的字段和不常用的字段进行拆分，为了减少操作时的冗余字段缓存。

### 垂直拆分

垂直拆分按列进行，若一张表包含的字段很多，则可以新建一张扩展表用于存放一些不常用的字段。这样就可以减小记录的长度，在以行为查找单位时，内存能加载更多的有效数据。高并发场景下，能一定程度上提高IO和数据库连接数。

#### 缺点

- 部分表无法 `join`只能通过接口聚合的方式实现，增加了开发难度
- 分布式事务处理复杂
- 依然存在单表数据量过大的问题，还需要进行水平拆分

### 水平拆分

当一个应用很难再以细粒度的垂直拆分，或者垂直拆分之后依然数据量巨大，存在单库读写、存储性能瓶颈时，就需要进行水平拆分。水平拆分分为库内分表和分库分表，是根据表内数据的内在逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表只包含一部分数据，从而使单个表的数据量变小，达到分布式的效果。

库内分表只解决了单表数据量过大了问题，并没有将表分步到不同机器上，依然存在同一个物理机的并发竞争。

#### 分片规则

1. **根据数值范围分**。如时间范围，ID 范围，冷热数据分离。**优点**是单表大小可控；便于扩展，无需对数据进行迁移；查找时可快速定位数据。**缺点**是存在热点数据，如按时间或自增ID的范围进行划分，热点数据总会被频繁读写，历史数据总是很少触及。
2. **根据数值取模。**类似hash分散，将数值进行取模分散到不同的表/库。**优点**是不容易出现热点问题和并发访问瓶颈。**缺点**是难以扩展，需要更改hash函数并且迁移数据（重新计算原有数据的hash值）

## 分库分表带来的问题

一般有这么五个问题：

1. 事务一致性问题
2. 跨节点关联查询 join 问题
3. 跨节点分页、排序、聚合函数问题
4. 全局主键避免重复问题
5. 数据迁移、扩容问题

### 1. 事务一致性问题

1. ###### **分布式事务**。当更新的数据在不同库中时，就会产生跨库事务问题，一般可使用"XA协议"和"两阶段提交"处理 。
2. **最终一致性**。对于岁系统实时一致性要求不高，只要在允许的时间内达到最终的一致性即可的系统，可采用事务补偿的方式。与事务在执行中发生错误立即回滚不同，事务补偿是一种事后检查补救的措施。常见方法有对数据进行对账检查，基于日志进行对比，定期同标准数据来源进行同步等等。

### 2. 跨节点关联查询 join 问题

切分之后，数据可能分布在不同节点上，join 操作比较麻烦，性能也不好，所以应避免使用 join，替代方法有：（详细内容参考前文链接）

#### 全局表

#### 字段冗余（防止join操作）

#### 应用层数据组装

### 3.跨节点分页、排序、聚合函数问题

主要是在执行以上这些操作（limit,order by）时，若涉及的数据不在同一个节点内，问题就会变得复杂。因为需要先在各个节点中执行一次操作，再将各节点的返回数据进行汇总，再进行一次操作。`order by`,`max`,`min`,`sum`,`count`等操作皆是如此。

### 4.全局主键避免重复问题

由于数据分散在不同表中，不同库中，甚至不同机器中，故原先的 ID 自增便无用武之地，因为针对一张表而自增的 ID 并不能保证全局唯一。故需要单独设计全局主键，避免跨库主键重复的问题。常用策略有：

#### UUID

是最简单的方案，但缺点也明显，UUID 比较长，会占用较多的内存。

#### 结合数据库维护主键 ID 表

新增一张主键表用来生成管理全局 ID 。这一方案的整体思想是：建立2个以上的全局ID生成的服务器，每个服务器上只部署一个数据库，每个库有一张sequence表用于记录当前全局ID。表中ID增长的步长是库的数量，起始值依次错开，这样能将ID的生成散列到各个数据库上。 由两个数据库服务器生成ID，设置不同的auto_increment值。第一台sequence的起始值为1，每次步长增长2，另一台的sequence起始值为2，每次步长增长也是2。结果第一台生成的ID都是奇数（1, 3, 5, 7 …），第二台生成的ID都是偶数（2, 4, 6, 8 …）。 

#### **Snowflake分布式自增ID算法** 

[美团Leaf](https://tech.meituan.com/MT_Leaf.html )

### 5.数据迁移、扩容问题 

当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。

此外还需要根据当前的数据量和QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过1000W）

如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。

## 支持分库分表的中间件

- sharding-jdbc（当当）：https://github.com/shardingjdbc
- TSharding（蘑菇街）：https://github.com/baihui212/tsharding
- Atlas（奇虎360）：https://github.com/Qihoo360/Atlas
- Cobar（阿里巴巴）：https://github.com/alibaba/cobar
- MyCAT（基于Cobar）：http://www.mycat.io/
- Oceanus（58同城）：https://github.com/58code/Oceanus
- Vitess（谷歌）：https://github.com/vitessio/vitess

# 数据库原理































